"""
This module provides asynchronous functions to process both structured JSON chunks
and unstructured free‑form documents for a given medical case identifier (MCID).

"""

from __future__ import annotations

import asyncio
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union


# ---------------------------------------------------------------------------
# Helper functions
#
# These helpers perform sorting and description lookup.  They do not depend
# on any asynchronous functionality and thus can be used synchronously.
# ---------------------------------------------------------------------------

def _natural_key(s: str) -> List[Union[str, int]]:
    """Return a key for natural sorting (case‑insensitive and numeric aware).

    This splits a string into runs of digits and non‑digits so that 'file10'
    sorts after 'file2' instead of between 'file1' and 'file2'.
    """
    return [int(text) if text.isdigit() else text.lower() for text in re.findall(r"\d+|\D+", s)]


def _sorted_chunk_files(folder: Path) -> List[Tuple[Path, int]]:
    """Return a list of (file_path, chunk_index) for all ``chunk*.txt`` files.

    Files are detected using a regular expression on the filename.  The chunk
    number extracted from the filename determines ordering.  For example,
    ``chunk_1.txt`` yields index 1, and will appear before ``chunk_2.txt``.
    Unmatched files are ignored.  The return list is sorted by the numeric
    chunk index.
    """
    chunk_pattern = re.compile(r"^chunk[_-]?(\d+)\.txt$", re.IGNORECASE)
    files: List[Tuple[Path, int]] = []
    for fp in folder.rglob("chunk*.txt"):
        match = chunk_pattern.match(fp.name)
        if match:
            try:
                idx = int(match.group(1))
            except ValueError:
                continue
            files.append((fp, idx))
    files.sort(key=lambda t: t[1])
    return files


def _sorted_doc_files(folder: Path) -> List[Path]:
    """Return a list of document text files sorted naturally by name.

    Only files with a ``.txt`` suffix at the top level of ``folder`` are
    included.  Sorting is case‑insensitive and numeric aware.
    """
    if not folder.exists() or not folder.is_dir():
        return []
    files = [fp for fp in folder.iterdir() if fp.is_file() and fp.suffix.lower() == ".txt"]
    files.sort(key=lambda p: _natural_key(p.name))
    return files


def _load_category_description(desc_dir: Path, category: str) -> str:
    """Attempt to load a description file for a given category.

    First tries an exact match of ``<category>.txt``.  If no exact match
    exists, performs a case‑ and punctuation‑insensitive lookup where any
    non‑alphanumeric characters are replaced with underscores.  Returns an
    empty string if no matching description is found or if an error occurs.
    """
    # Exact match
    exact = desc_dir / f"{category}.txt"
    if exact.exists() and exact.is_file():
        try:
            return exact.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            return ""

    # Case/punctuation normalised match
    def normalise(name: str) -> str:
        return re.sub(r"[^a-z0-9]+", "_", name.lower()).strip("_")

    target = normalise(category)
    for fp in desc_dir.glob("*.txt"):
        if normalise(fp.stem) == target:
            try:
                return fp.read_text(encoding="utf-8", errors="ignore")
            except Exception:
                return ""
    return ""


# ---------------------------------------------------------------------------
# Asynchronous processing helpers
#
# These functions use asyncio to process multiple files concurrently.  They
# accept prompt templates with placeholders and yield dictionaries of results.
# ---------------------------------------------------------------------------

async def _marshal_text(
    text: str,
    schema: Any,
    params: Dict[str, Any],
    prompt_template: str,
    placeholder: str,
    sem: asyncio.Semaphore,
) -> Any:
    """Marshal a single text through the hc4sass client with concurrency control.

    The provided ``prompt_template`` must contain a named placeholder (e.g.
    ``{json_context}`` or ``{doc_context}``).  The placeholder name is passed
    via the ``placeholder`` argument and will be replaced with the text.  All
    other format fields must already be resolved in the template.  This helper
    returns the raw result from ``hc4sass.marshal_into_json``.  If the global
    ``hc4sass`` client is not available, an error string is returned instead.
    """
    async with sem:
        try:
            prompt = prompt_template.format(**{placeholder: text})
            return await hc4sass.marshal_into_json(
                schema=schema,
                prompt=prompt,
                params=params,
            )
        except Exception as exc:
            # Catch any exception and return a structured error
            return {"_error": str(exc)}


async def _process_json_category(
    category_path: Path,
    chat_schema: Any,
    params_4o: Dict[str, Any],
    chat_prompt_template: str,
    desc_text: str,
    max_concurrency: int,
) -> Dict[str, Any]:
    """Process all chunk files under a single JSON category folder.

    Loads each ``chunk*.txt`` file, fills the ``{json_context}`` placeholder
    with its content and the ``{json_desc}`` placeholder with ``desc_text``,
    then calls the ``hc4sass.marshal_into_json`` service asynchronously.  The
    results are gathered into a dictionary keyed by ``chunk_<index>``.
    """
    # Preformat the prompt with the description once to avoid repeated work.
    if "{json_desc}" not in chat_prompt_template:
        raise ValueError("chat_prompt_template must contain {json_desc}")
    if "{json_context}" not in chat_prompt_template:
        raise ValueError("chat_prompt_template must contain {json_context}")

    prompt_with_desc = chat_prompt_template.format(json_desc=desc_text)
    sem = asyncio.Semaphore(max_concurrency)
    tasks: List[asyncio.Task] = []
    chunk_files = _sorted_chunk_files(category_path)

    for fp, idx in chunk_files:
        try:
            text = fp.read_text(encoding="utf-8", errors="ignore")
        except Exception as exc:
            # If the file cannot be read, record an error immediately
            tasks.append(asyncio.create_task(asyncio.sleep(0, {"_error": f"Failed to read {fp}: {exc}"})))
            continue
        tasks.append(
            asyncio.create_task(
                _marshal_text(
                    text=text,
                    schema=chat_schema,
                    params=params_4o,
                    prompt_template=prompt_with_desc,
                    placeholder="json_context",
                    sem=sem,
                )
            )
        )

    results: Dict[str, Any] = {}
    gathered = await asyncio.gather(*tasks, return_exceptions=False)
    for (fp, idx), res in zip(chunk_files, gathered):
        key = f"chunk_{idx}"
        # If res is a coroutine exception, it will be captured above; no need to
        # distinguish here.  We simply assign the result as is.
        results[key] = res
    return results


async def _process_document_files(
    docs_path: Path,
    doc_schema: Any,
    doc_params: Dict[str, Any],
    doc_prompt_template: str,
    max_concurrency: int,
) -> Dict[str, Any]:
    """Process each document file under ``docs_path`` with its own chunk key.

    Each ``.txt`` file in the folder is treated as a single chunk.  The
    ``doc_prompt_template`` must contain the ``{doc_context}`` placeholder
    which will be replaced by the file content.  The results are grouped in
    a dictionary keyed by the document filename; within each entry, the key
    ``chunk_<n>`` is assigned according to the document's order (1‑based).
    """
    if "{doc_context}" not in doc_prompt_template:
        raise ValueError("doc_prompt_template must contain {doc_context}")

    sem = asyncio.Semaphore(max_concurrency)
    tasks: List[asyncio.Task] = []
    doc_files = _sorted_doc_files(docs_path)
    # We assign a global chunk index across all documents starting from 1.
    # Each document will get its own index.  If a document fails to read,
    # an error entry is returned for that document.
    for fp in doc_files:
        try:
            text = fp.read_text(encoding="utf-8", errors="ignore")
        except Exception as exc:
            tasks.append(asyncio.create_task(asyncio.sleep(0, {"_error": f"Failed to read {fp}: {exc}"})))
            continue
        tasks.append(
            asyncio.create_task(
                _marshal_text(
                    text=text,
                    schema=doc_schema,
                    params=doc_params,
                    prompt_template=doc_prompt_template,
                    placeholder="doc_context",
                    sem=sem,
                )
            )
        )

    results: Dict[str, Any] = {}
    gathered = await asyncio.gather(*tasks, return_exceptions=False)
    for idx, (fp, res) in enumerate(zip(doc_files, gathered), start=1):
        # Use the document filename as the top‑level key.  Within that, assign
        # a single chunk key "chunk_<n>" based on the document's order.
        results.setdefault(fp.name, {})[f"chunk_{idx}"] = res
    return results


async def marshal_json_and_docs(
    mcid: str,
    json_base_path: Union[str, Path],
    docs_base_path: Union[str, Path],
    json_categories: List[str],
    json_schema: Any,
    json_params: Dict[str, Any],
    json_prompt_template: str,
    desc_dir: Union[str, Path],
    doc_schema: Any,
    doc_params: Dict[str, Any],
    doc_prompt_template: str,
    json_concurrency: int = 8,
    doc_concurrency: int = 8,
) -> Dict[str, Any]:
    """Process JSON categories and document files concurrently for a given MCID.

    Parameters
    ----------
    mcid: str
        The medical case identifier.  This value is included in the output
        dictionary for reference.
    json_base_path: str or Path
        Path to the directory containing category subdirectories for the MCID,
        e.g. ``.../Normalised_Input_Jsons/<MCID>``.
    docs_base_path: str or Path
        Path to the directory containing free‑form document files for the MCID,
        e.g. ``.../Normalised_Input_Docs/<MCID>``.
    json_categories: List[str]
        A list of category names (subdirectory names under ``json_base_path``)
        to process.  If the list is empty, ``"message": "Information is not
        available."`` is returned for the JSON portion.
    json_schema: Any
        Schema definition passed directly to ``hc4sass.marshal_into_json``
        for JSON category processing.
    json_params: Dict[str, Any]
        Parameters passed directly to ``hc4sass.marshal_into_json`` for
        JSON category processing.
    json_prompt_template: str
        Prompt template used for JSON categories.  Must contain
        ``{json_context}`` and ``{json_desc}`` placeholders.
    desc_dir: str or Path
        Directory containing category description files named ``<category>.txt``.
        Each category will attempt to load its own description from this
        directory.
    doc_schema: Any
        Schema definition passed directly to ``hc4sass.marshal_into_json``
        for document processing.
    doc_params: Dict[str, Any]
        Parameters passed directly to ``hc4sass.marshal_into_json`` for
        document processing.
    doc_prompt_template: str
        Prompt template used for documents.  Must contain the
        ``{doc_context}`` placeholder.  No description is automatically
        substituted for documents.
    json_concurrency: int, optional
        Maximum number of concurrent tasks across all chunk files in a single
        JSON category.  Defaults to 8.
    doc_concurrency: int, optional
        Maximum number of concurrent tasks across all document files.  Defaults
        to 8.

    Returns
    -------
    Dict[str, Any]
        A dictionary with the following structure::

            {
                "mcid": mcid,
                "json": {
                    <category_name>: {
                        "chunk_1": result,
                        "chunk_2": result,
                        ...
                    },
                    ...
                } | {"message": "Information is not available."},
                "documents": {
                    <doc_filename>: {
                        "chunk_<n>": result
                    },
                    ...
                } | {"message": "Information is not available."}
            }

        If a category or documents path does not exist or yields no files,
        a ``message`` field is used instead of an empty dictionary.
    """
    json_base = Path(json_base_path)
    docs_base = Path(docs_base_path)
    desc_dir_path = Path(desc_dir)

    # Schedule tasks for each JSON category
    async def process_categories() -> Dict[str, Any]:
        if not json_categories:
            return {"message": "Information is not available."}
        tasks: List[asyncio.Task] = []
        keys: List[str] = []
        for category in json_categories:
            cat_path = json_base / category
            if not cat_path.exists() or not cat_path.is_dir():
                # Non‑existent category yields an immediate error entry
                keys.append(category)
                tasks.append(asyncio.create_task(asyncio.sleep(0, {"_error": f"Category path not found: {cat_path}"})))
                continue
            # Load the description for this category
            desc_text = _load_category_description(desc_dir_path, category)
            keys.append(category)
            tasks.append(
                asyncio.create_task(
                    _process_json_category(
                        category_path=cat_path,
                        chat_schema=json_schema,
                        params_4o=json_params,
                        chat_prompt_template=json_prompt_template,
                        desc_text=desc_text,
                        max_concurrency=json_concurrency,
                    )
                )
            )
        results: Dict[str, Any] = {}
        gathered = await asyncio.gather(*tasks, return_exceptions=False)
        for name, res in zip(keys, gathered):
            results[name] = res
        return results

    # Schedule document processing
    async def process_docs() -> Dict[str, Any]:
        if not docs_base.exists() or not docs_base.is_dir():
            return {"message": "Information is not available."}
        return await _process_document_files(
            docs_path=docs_base,
            doc_schema=doc_schema,
            doc_params=doc_params,
            doc_prompt_template=doc_prompt_template,
            max_concurrency=doc_concurrency,
        )

    # Run both tasks concurrently
    json_task = asyncio.create_task(process_categories())
    docs_task = asyncio.create_task(process_docs())
    json_results, docs_results = await asyncio.gather(json_task, docs_task)

    return {
        "mcid": mcid,
        "json": json_results,
        "documents": docs_results,
    }


__all__ = [
    "marshal_json_and_docs",
    "_process_json_category",
    "_process_document_files",
    "_load_category_description",
    "_sorted_chunk_files",
    "_sorted_doc_files",
]
