import json
import os

import streamlit as st
import openai
import tiktoken

# --------------------------------------------------
# Constants
# --------------------------------------------------
MAX_CONTEXT_TOKENS = 30000  # cap for each uploaded file

# --------------------------------------------------
# Utility functions
# --------------------------------------------------

def file_to_string(uploaded_file):
    """Read an uploaded file and return its text content (best‚Äëeffort decoding)."""
    if uploaded_file is None:
        return ""

    content_bytes = uploaded_file.read()
    for enc in ("utf-8", "latin-1", "cp1252"):
        try:
            return content_bytes.decode(enc)
        except UnicodeDecodeError:
            continue
    # fallback to binary repr if all decode attempts fail
    return str(content_bytes)


def count_tokens(text: str, encoder) -> int:
    """Count tokens in *text* using *encoder*."""
    return len(encoder.encode(text))


def trim_to_tokens(text: str, limit: int, encoder):
    """Trim *text* to *limit* tokens if necessary and return (trimmed_text, token_count, was_trimmed)."""
    tokens = encoder.encode(text)
    if len(tokens) <= limit:
        return text, len(tokens), False
    trimmed_text = encoder.decode(tokens[:limit])
    return trimmed_text, limit, True


def build_context(file1_text: str, file2_text: str) -> str:
    """Merge the two FHIR documents into a single context block."""
    return (
        "File 1 (FHIR JSON):\n" + file1_text.strip() +
        "\n\nFile 2 (FHIR JSON):\n" + file2_text.strip()
    )


def init_openai(api_key: str):
    if not api_key:
        raise ValueError("Please provide an OpenAI API key in the sidebar.")
    openai.api_key = api_key

# --------------------------------------------------
# Streamlit page config
# --------------------------------------------------

st.set_page_config(
    page_title="FHIR Comparison Chatbot",
    page_icon="ü©∫",
    layout="wide",
)

# --------------------------------------------------
# Sidebar ‚Äì inputs & settings
# --------------------------------------------------

st.sidebar.header("Settings")
api_key = st.sidebar.text_input("üîë OpenAI API Key", type="password")

file1 = st.sidebar.file_uploader("üìÑ Upload FHIR JSON ‚Äì File 1", type=["json"], key="file1")
file2 = st.sidebar.file_uploader("üìÑ Upload FHIR JSON ‚Äì File 2", type=["json"], key="file2")

system_prompt = st.sidebar.text_area(
    "üìù System Prompt (optional)",
    height=150,
    placeholder="Add additional instructions for the assistant here‚Ä¶",
)

# Token encoder
encoder = tiktoken.get_encoding("cl100k_base")

# Read & trim files
file1_raw = file_to_string(file1)
file2_raw = file_to_string(file2)

file1_text, file1_tokens, file1_trimmed = trim_to_tokens(file1_raw, MAX_CONTEXT_TOKENS, encoder)
file2_text, file2_tokens, file2_trimmed = trim_to_tokens(file2_raw, MAX_CONTEXT_TOKENS, encoder)

if file1:
    lbl = "File 1 Tokens" + (f" (trimmed to {MAX_CONTEXT_TOKENS})" if file1_trimmed else "")
    st.sidebar.markdown(f"**{lbl}:** {file1_tokens}")

if file2:
    lbl = "File 2 Tokens" + (f" (trimmed to {MAX_CONTEXT_TOKENS})" if file2_trimmed else "")
    st.sidebar.markdown(f"**{lbl}:** {file2_tokens}")

# --------------------------------------------------
# Main Chat Area
# --------------------------------------------------

st.title("ü©∫ FHIR Comparison Chatbot")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Render chat history
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# User prompt
user_query = st.chat_input("Ask your question about the two FHIR files‚Ä¶")

if user_query:
    if not api_key:
        st.error("Please provide your OpenAI API key in the sidebar.")
    elif not file1 or not file2:
        st.error("Please upload **both** FHIR JSON files before asking a question.")
    else:
        # Display user message
        st.session_state.messages.append({"role": "user", "content": user_query})
        with st.chat_message("user"):
            st.markdown(user_query)

        # Build OpenAI messages
        context = build_context(file1_text, file2_text)
        messages = []
        if system_prompt.strip():
            messages.append({"role": "system", "content": system_prompt.strip()})
        messages.append({"role": "system", "content": context})
        messages.append({"role": "user", "content": user_query})

        # Call ChatCompletion
        try:
            init_openai(api_key)
            response = openai.ChatCompletion.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.2,
                max_tokens=1024,
            )
            assistant_reply = response.choices[0].message["content"].strip()
        except Exception as e:
            assistant_reply = f"üö® OpenAI API error: {e}"

        # Display assistant response
        st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
        with st.chat_message("assistant"):
            st.markdown(assistant_reply)

# --------------------------------------------------
# Footer ‚Äì how to run
# --------------------------------------------------

with st.expander("‚ÑπÔ∏è  How to run this app"):
    st.markdown(
        """
        1. **Install dependencies**
           ```bash
           pip install streamlit openai tiktoken
           ```
        2. **Save this script** as `streamlit_fhir_chatbot.py`.
        3. **Run**
           ```bash
           streamlit run streamlit_fhir_chatbot.py
           ```
        4. Enter your OpenAI key, upload the two FHIR JSON files (they will be trimmed to 30‚ÄØ000 tokens each if larger), add an optional system prompt, and start chatting!
        """
    )
