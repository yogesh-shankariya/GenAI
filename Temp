def session_exists(session_id: str) -> bool:
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT 1 FROM application_logs WHERE session_id = ? LIMIT 1", (session_id,))
    result = cursor.fetchone()
    conn.close()
    return result is not None



from pathlib import Path
import sys
import json
import traceback
import argparse
from typing import List, Dict, Optional
import logging

from src.utils.config_loader import load_config
from src.utils.logger import setup_logger
from src.services.llm_client import LLMClient
from src.utils.file_and_session_manager import FileHandler
from src.utils.sql_db import (
    get_chat_history,
    insert_application_logs,
    session_exists,
)


def first_message(file_content: str, user_question: str) -> List[Dict[str, str]]:
    return [
        {
            "role": "system",
            "content": "You are a helpful assistant. You will be given a medical chart and you will be asked questions on the same."
        },
        {
            "role": "user",
            "content": f"Medical chart:\n{file_content}\n\nQuestion: {user_question}\nProvide evidence of the line in your answer."
        }
    ]


def process_request(
    session_id: str,
    user_question: str,
    llm_client: LLMClient,
    file_handler: FileHandler,
    file_path: Optional[str] = None,
    logger: Optional[logging.Logger] = None
) -> str:
    try:
        is_new_session = not session_exists(session_id)

        if is_new_session and not file_path:
            logger.error(f"File path is required for new session: {session_id}")
            return json.dumps({"session_id": session_id, "error": "File path is required for new sessions"})

        # Always load context fresh from source
        file_content = file_handler.process_files_from_api_sequential(file_path, start_seq=1)

        # Build message history
        messages = get_chat_history(session_id)
        messages.insert(0, {
            "role": "system",
            "content": "You are a helpful assistant. You will be given a medical chart and you will be asked questions on the same."
        })
        messages.append({
            "role": "user",
            "content": f"Medical chart:\n{file_content}\n\nQuestion: {user_question}\nProvide evidence of the line in your answer."
        })

        # Generate and store response
        response = llm_client.query_with_memory(messages)
        insert_application_logs(session_id, user_question, response)

        logger.info(f"Handled {'first' if is_new_session else 'follow-up'} message for session: {session_id}")
        return json.dumps({"session_id": session_id, "content": response})

    except Exception as e:
        logger.exception(f"Unexpected error: {str(e)}")
        return json.dumps({"session_id": session_id, "error": f"Unexpected error: {str(e)}"})


def main() -> str:
    try:
        config = load_config()
        logger = setup_logger(config["logging"])
        llm_client = LLMClient(config["llm"], logger)
    except Exception as e:
        print(f"Failed to initialize components: {str(e)}")
        print(traceback.format_exc())
        sys.exit(1)

    parser = argparse.ArgumentParser(description='Process chat session inputs.')
    parser.add_argument('session_id', type=str, help='Session identifier')
    parser.add_argument('--file_path', type=str, help='Path to text file (required for new sessions)')
    parser.add_argument('user_question', type=str, help='User question')
    args = parser.parse_args()

    file_handler = FileHandler(logger)

    return process_request(
        session_id=args.session_id,
        user_question=args.user_question,
        llm_client=llm_client,
        file_handler=file_handler,
        file_path=args.file_path,
        logger=logger
    )


if __name__ == "__main__":
    result = main()
    print(result)
