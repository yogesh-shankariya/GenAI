Here’s a crisp, slide-ready summary you can paste into your PPT.

**Data Sources**

* FHIR stores and HOSCDA for structured clinical data.
* Clinical PDFs/docs in S3 for unstructured evidence.
* Combines real-time facts with reference knowledge.

**Data Integration (Horizon Ingestion API + MCP)**

* Horizon extracts text/metadata from PDFs and indexes them.
* MCP securely connects to live FHIR/HOSCDA endpoints.
* Delivers a unified access layer with governance.

**Retrieval (Hybrid RAG)**

* Semantic + keyword (BM25) + filters for high recall/precision.
* Intent mapping chooses best source (docs vs FHIR).
* Function-calling fetches exact records or tools.
* Returns compact, cite-able context to the LLM.

**LLM Orchestration (via MCP & Agents)**

* Routes each query through retrieval, tools, and agents.
* Builds/cleans prompts, enforces moderation, assembles final context.
* Manages multi-step tool calls and retries; handles streaming.

**Chat Agents**

* Intent classification to pick workflow.
* Guardrails (policy, safety, PHI hygiene, scope control).
* Fallback/escalation when confidence is low or out-of-scope.
* Horizon API wrapper standardizes tool/use-case actions.

**Large Language Models (LLM)**

* Generates answers grounded in retrieved context.
* Handles reasoning, summarization, and citation stitching.
* Supports streaming responses for better UX.

**Chat Interface (TMV)**

* User UI (web/Teams/etc.) with follow-ups and history.
* Shows key sources/snippets; supports quick clarifications.

**Observability & Governance**

* Audit logs of chats, data calls, and decisions.
* Latency/cost dashboards; RAG quality metrics.
* Human-in-the-Loop review and feedback loop for continuous improvement.

**Common Services**

* Authentication/authorization, secrets, and rate limiting.
* Cache, session/memory, prompt registry, similarity search.
* Centralized logging, error handling, and configuration.

**End-to-End Flow (at a glance)**

1. User asks → 2) Intent classified → 3) Retrieve (docs/FHIR) →
2. Orchestrate via MCP/agents → 5) LLM generates grounded answer →
3. Logs/metrics captured; HITL if needed.
