from pathlib import Path
import sys
import json
import traceback
import argparse
from typing import List, Dict, Optional
import logging

from src.utils.config_loader import load_config
from src.utils.logger import setup_logger
from src.services.llm_client import LLMClient
from src.utils.file_and_session_manager import FileHandler
from src.utils.sql_db import (
    get_chat_history,
    insert_conversation,
    session_exists,
    create_conversation_table,
)


def process_request(
    session_id: str,
    user_question: str,
    llm_client: LLMClient,
    file_handler: FileHandler,
    file_path: Optional[str] = None,
    logger: Optional[logging.Logger] = None
) -> str:
    try:
        is_new_session = not session_exists(session_id)

        if is_new_session and not file_path:
            logger.error(f"File path is required for new session: {session_id}")
            return json.dumps({"session_id": session_id, "error": "File path is required for new sessions"})

        # Always get context
        file_content = file_handler.process_files_from_api_sequential(file_path, start_seq=1)

        # Build messages: 1. system + context, 2. chat history, 3. latest user Q
        messages = [
            {
                "role": "system",
                "content": (
                    "You are a helpful assistant. You will be given a medical chart and you will be asked questions on the same.\n\n"
                    f"Here is the medical chart:\n{file_content}"
                )
            }
        ]

        # Add historical Q&A
        history = get_chat_history(session_id)
        messages.extend(history)

        # Add current question
        messages.append({
            "role": "user",
            "content": f"Question: {user_question}\nProvide evidence of the line in your answer."
        })

        # Query LLM
        response = llm_client.query_with_memory(messages)

        # Log to SQLite
        insert_conversation(session_id, user_question, response)

        logger.info(f"Handled {'first' if is_new_session else 'follow-up'} message for session: {session_id}")
        return json.dumps({"session_id": session_id, "content": response})

    except Exception as e:
        logger.exception(f"Unexpected error: {str(e)}")
        return json.dumps({"session_id": session_id, "error": f"Unexpected error: {str(e)}"})


def main() -> str:
    try:
        config = load_config()
        logger = setup_logger(config["logging"])
        create_conversation_table()
        llm_client = LLMClient(config["llm"], logger)
    except Exception as e:
        print(f"Failed to initialize components: {str(e)}")
        print(traceback.format_exc())
        sys.exit(1)

    parser = argparse.ArgumentParser(description='Process chat session inputs.')
    parser.add_argument('session_id', type=str, help='Session identifier')
    parser.add_argument('--file_path', type=str, help='Path to text file (required for new sessions)')
    parser.add_argument('user_question', type=str, help='User question')
    args = parser.parse_args()

    file_handler = FileHandler(logger)

    return process_request(
        session_id=args.session_id,
        user_question=args.user_question,
        llm_client=llm_client,
        file_handler=file_handler,
        file_path=args.file_path,
        logger=logger
    )


if __name__ == "__main__":
    result = main()
    print(result)
