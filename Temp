from pathlib import Path
from typing import Any, Dict, List, Tuple
import json
from transformers import AutoTokenizer

MODEL_NAME = "mixedbread-ai/mxbai-embed-large-v1"
TOKEN_LIMIT = 512

tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)

def count_tokens(text: str) -> int:
    # Count with special tokens, no truncation
    return len(tok.encode(text, add_special_tokens=True))

def record_to_text(record: Dict[str, Any]) -> str:
    # Same canonicalization as your preprocessing
    return json.dumps(record, sort_keys=True, ensure_ascii=False)
