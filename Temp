import json
import re
from pathlib import Path
from collections import defaultdict, OrderedDict
from typing import Union, List, Dict

PAGE_RE = re.compile(r"page-(\d+)\.json$", re.IGNORECASE)

def _pages_in(dir_path: Path) -> List[Path]:
    """Return sorted page-*.json files in a folder (by page number)."""
    pages = []
    for p in dir_path.glob("page-*.json"):
        m = PAGE_RE.search(p.name)
        if m:
            pages.append((int(m.group(1)), p))
    pages.sort(key=lambda x: x[0])
    return [p for _, p in pages]

def _gather_case_folders(json_root: Path) -> List[Path]:
    """Find all folders that contain at least one page-*.json."""
    folders = set()
    for p in json_root.rglob("page-*.json"):
        folders.add(p.parent)
    return sorted(folders)

def combine_page_jsons(
    json_root: Union[str, Path],
    output_root: Union[str, Path, None] = None,
    combined_filename: str = "combined.json",
    false_reason_msg: str = "no supporting text on all the page"
) -> List[str]:
    """
    For every folder under `json_root` that contains page-*.json:
      - merge results by 'name'
      - keep only entries with value == True, recording page number, value, evidence, reason
      - if a step has no True anywhere, emit a single {value:false, reason:false_reason_msg}
    Write one combined JSON per folder, mirroring hierarchy under `output_root` (or in-place if None).

    Returns list of written file paths.
    """
    json_root = Path(json_root).resolve()
    out_root = Path(output_root).resolve() if output_root else None

    written: List[str] = []
    case_folders = _gather_case_folders(json_root)

    for case_dir in case_folders:
        # Determine output path (mirror hierarchy if output_root is provided)
        if out_root:
            rel = case_dir.relative_to(json_root)
            out_dir = (out_root / rel)
        else:
            out_dir = case_dir
        out_dir.mkdir(parents=True, exist_ok=True)
        out_file = out_dir / combined_filename

        # Accumulate hits by step-name
        hits_by_name: Dict[str, List[OrderedDict]] = defaultdict(list)
        step_order: List[str] = []

        pages = _pages_in(case_dir)
        for page_path in pages:
            page_text = page_path.read_text(encoding="utf-8") or "{}"
            try:
                data = json.loads(page_text)
            except json.JSONDecodeError:
                data = {}

            results = data.get("results", [])
            # record order the first time we see a step name
            for item in results:
                nm = item.get("name")
                if nm is None:
                    continue
                if nm not in step_order:
                    step_order.append(nm)

            # collect True entries
            m = PAGE_RE.search(page_path.name)
            page_no = int(m.group(1)) if m else None
            for item in results:
                if item.get("value") is True:
                    nm = item.get("name")
                    if nm is None:
                        continue
                    entry = OrderedDict()
                    entry["page"] = page_no
                    entry["value"] = True
                    entry["evidence"] = item.get("evidence", [])
                    entry["reason"] = item.get("reason", "")
                    hits_by_name[nm].append(entry)

        # Build combined output preserving step order
        combined = []
        for nm in step_order:
            obj = OrderedDict()
            obj["name"] = nm
            if hits_by_name.get(nm):  # at least one True somewhere
                obj["results"] = hits_by_name[nm]
            else:
                obj["results"] = [OrderedDict([("value", False), ("reason", false_reason_msg)])]
            combined.append(obj)

        # Persist
        out_file.write_text(json.dumps(combined, ensure_ascii=False, indent=2), encoding="utf-8")
        written.append(str(out_file))
        print(f"Wrote: {out_file}")

    # Summary
    print(f"\nFolders processed: {len(case_folders)}")
    return written
