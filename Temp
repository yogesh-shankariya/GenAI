import re
from typing import List, Dict

# ── patterns ──────────────────────────────────────────────────────────────────
# 1. Page-start tag *with* a number → used to detect page boundaries.
TAG_DETECT = re.compile(r"<ocr_service_page_start>(\d+)", re.IGNORECASE)

# 2. Page-start tag with *optional* number → used to purge all tags later.
TAG_STRIP  = re.compile(r"<ocr_service_page_start>\d*", re.IGNORECASE)

def get_page_context(pages: List[int], full_text: str) -> Dict[str, str]:
    """
    Extract slices of `full_text` that fall between successive
    <ocr_service_page_start>N markers.

    Parameters
    ----------
    pages      : list[int]
        Page numbers you want to pull out (e.g. [2, 5]).
    full_text  : str
        String containing repeated tags like
        '<ocr_service_page_start>1', '<ocr_service_page_start>2', …

    Returns
    -------
    dict[str, str]
        Example → {'Page-2': '…', 'Page-5': '…'}
        All tag remnants are removed from each slice.
    """
    # ── 1. find every tag + its position ──────────────────────────────────────
    starts = []                               # (page_no, slice_start_pos)
    for m in TAG_DETECT.finditer(full_text):
        starts.append((int(m.group(1)), m.end()))

    # No tags → nothing to extract
    if not starts:
        return {}

    # ── 2. add sentinel so the last page has an end bound ─────────────────────
    starts.sort(key=lambda t: t[1])           # sort by file order
    starts.append((None, len(full_text)))

    # ── 3. compute (start, end) for each page ─────────────────────────────────
    bounds = {}
    for (pg, s), (_, nxt) in zip(starts, starts[1:]):
        if pg is not None:
            bounds[pg] = (s, nxt)

    # ── 4. slice, strip tags, and package result ──────────────────────────────
    out = {}
    for p in pages:
        if p in bounds:
            s, e = bounds[p]
            snippet = full_text[s:e]
            snippet = TAG_STRIP.sub("", snippet).strip()
            out[f"Page-{p}"] = snippet

    return out
