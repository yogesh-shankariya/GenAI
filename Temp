from pathlib import Path
import sys
import json
import traceback
import argparse
from typing import List, Dict, Optional
import logging

from src.utils.config_loader import load_config
from src.utils.logger import setup_logger
from src.services.llm_client import LLMClient
from src.utils.file_and_session_manager import FileHandler, SessionManager
from src.utils.sql_db import get_chat_history, insert_application_logs


def first_message(file_content: str, user_question: str) -> List[Dict[str, str]]:
    return [
        {
            "role": "system",
            "content": "You are a helpful assistant. You will be given a medical chart and you will be asked questions on the same."
        },
        {
            "role": "user",
            "content": f"Medical chart:\n{file_content}\n\nQuestion: {user_question}\nProvide evidence of the line in your answer."
        }
    ]


def process_request(
    session_id: str,
    user_question: str,
    llm_client: LLMClient,
    session_manager: SessionManager,
    file_handler: FileHandler,
    file_path: Optional[str] = None,
    logger: Optional[logging.Logger] = None
) -> str:
    try:
        is_new_session = not session_manager.session_exists(session_id)

        # Handle new session
        if is_new_session:
            if not file_path:
                logger.error(f"File path is required for new session: {session_id}")
                return json.dumps({"session_id": session_id, "error": "File path is required for new sessions"})
            session_manager.create_session(session_id, file_path)

        # Load context for both new & existing sessions
        file_content = file_handler.process_files_from_api_sequential(file_path, start_seq=1)

        # Load past messages from DB
        messages = get_chat_history(session_id)
        messages.insert(0, {
            "role": "system",
            "content": "You are a helpful assistant. You will be given a medical chart and you will be asked questions on the same."
        })
        messages.append({
            "role": "user",
            "content": f"Medical chart:\n{file_content}\n\nQuestion: {user_question}\nProvide evidence of the line in your answer."
        })

        # Generate answer from LLM
        response = llm_client.query_with_memory(messages)

        # Log question/answer into DB
        insert_application_logs(session_id, user_question, response)

        logger.info(f"Completed handling {'first' if is_new_session else 'follow-up'} message for session: {session_id}")
        return json.dumps({"session_id": session_id, "content": response})

    except IOError as e:
        logger.error(f"IO error: {str(e)}")
        return json.dumps({"session_id": session_id, "error": f"IO error: {str(e)}"})

    except Exception as e:
        logger.exception(f"Unexpected error: {str(e)}")
        return json.dumps({"session_id": session_id, "error": f"Unexpected error: {str(e)}"})


def main() -> str:
    try:
        config = load_config()
        logger = setup_logger(config["logging"])
        llm_client = LLMClient(config["llm"], logger)
    except Exception as e:
        print(f"Failed to initialize components: {str(e)}")
        print(traceback.format_exc())
        sys.exit(1)

    parser = argparse.ArgumentParser(description='Process chat session inputs.')
    parser.add_argument('session_id', type=str, help='Session identifier')
    parser.add_argument('--file_path', type=str, help='Path to text file (optional)')
    parser.add_argument('user_question', type=str, help='User question')
    args = parser.parse_args()

    file_handler = FileHandler(logger)
    session_manager = SessionManager(logger)

    return process_request(
        session_id=args.session_id,
        user_question=args.user_question,
        llm_client=llm_client,
        session_manager=session_manager,
        file_handler=file_handler,
        file_path=args.file_path,
        logger=logger
    )


if __name__ == "__main__":
    result = main()
    print(result)
